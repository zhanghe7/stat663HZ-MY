{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> STA663 Statistical Computation Final Project </center></h1>\n",
    "<h2><center> Implementatiton of Latent Dirichlet Allocation(LDA) </center></h2>\n",
    "<h3><center> Hengqian Zhang, Mengrui Yin </center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zhanghe7/stat663HZ-MY.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$Latent Dirichlet Allocation is a generative probabilistic model to deal with discrete data such as text corpora. In this report, we implemented the algorithm in the paper ”Latent Dirichlet Allocation”(David M. Blei, Andrew Y.Ng, Michael I. Jordan) with Gibbs Sampler and Variatioanl Inference, compared results of these two methods, performed code testing to ensure correctness and optimized the Python code with Cython to make our work faster. Simulation is used for generating small text set to do inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1  Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$The paper we selected is \"Latent Dirichlet Allocation\"(David M. Blei, Andrew Y. Ng, Michael I. Jordan). One of our homework about tf-idf scheme intrigued our interests about text modeling, so we selected this paper to implement. tf-idf did not concern latent relationships between words. The situation of two documents with few common words but are similar cannot be analyzed by tf-idf. So LDA did great improvement. It is much more complex than tf-idf with better performance. It is a three level hierarchical Bayesian model including words, topics, documents. Text corpora is a collection of documents and each document is a mixture distributions over topics. Each topic is a mixture distribution over words under this topic. Due to difficulty of computation, LDA applied variational methods and an EM algorithm for parameter estimates and inference.<br> \n",
    "$\\quad$ The alternative method to deal with compuation difficulty is Gibbs Sampler. LDA is an unsupervised machine learning algorithm, which is used to recognize latent topics of big dataset of text such as corpus. It is a powerful tool for text data set. It can be used for document modeling,classification and filtering. In LDA algorithm, words in all doucuments are regarded as a VOCABULARY and we regard VOCABULARY as word bag, which is no order between words. So, LDA simplifies complexity of topic inference. In our project, we implemented LDA algorithm and applied it on texts to find top words of each topics.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Algorithm Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 define terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A **word** is defined as a item from a VOCABULARY with index\n",
    "$\\{$1$\\cdots$V$\\}$<br>\n",
    "* A **document** is a sequence of N words denoted by $\\vec{w}$ = $\\{$ w$_1$,w$_2$ $\\cdots$ w$_N$ $\\}$,where w$_n$ is the nth word of the document <br>\n",
    "* A **corpus** is a collection of M documents denoted by $D = { \\vec{w_1},\\vec{w_2} \\cdots \\vec{w_M} }$, where $\\vec{w_m}$ represents document m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA assumes the following generative process for each document\n",
    "$\\vec{w}$ in a corpus D:\n",
    "1. Choose N $\\sim$ Poisson($\\xi$)\n",
    "2. Choose $\\vec{\\theta}$ $\\sim$ Dir($\\vec{\\alpha}$)\n",
    "3. For each of the N words w$_n$:<br>\n",
    "(a) Choose a topic z$_n$ $\\sim$ Multinomial($\\vec{\\theta}$)<br> \n",
    "(b) Choose a word w$_n$ from p(w$_n$ $|$ z$_n$,$\\vec{\\beta}$), a Multinomial probability conditioned on the topic z$_n$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* N: the number of words in a document <br> \n",
    "* K: the number of topics <br> \n",
    "* $\\vec{\\alpha}$: a vector with k dimension, hyper-parameter of distribution of document-topic <br>\n",
    "* $\\vec{\\beta}$: a matrix, a distribution of topic-word<br>\n",
    "* $\\vec{\\theta}$: the vector of ${p(z_n | d)}$ with K dimension, d denotes the document. $\\vec{\\theta}$ can be denoted  as $\\{p_{t1} \\cdots p_{tk}\\}$, where p$_{ti}$ represents the probability of topic i in the document d. $\\theta_m$ is the topic distribution of document m<br>\n",
    "* z$_n$: the index of topic of nth word in the document<br>\n",
    "* w$_n$: the index of nth word<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows the process of LDA<br>\n",
    "<br>\n",
    "![caption](files/LDA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$The graphs above shows the process of LDA. The outer frame is corpus which is made up of M single document. The inner frame has tow components: words(circle w) and topics(circle z). The graph clearly demonstrate the process of LDA. $\\alpha$ is parameter of $\\theta$. $\\theta$ is a  distribution of document-topic whose prior is Dirichlet Distribution. Topic z is sampled from a mixture distribution over topics, so it is sampled for multinomial($\\theta$). After obtaining topic, we can find distribution of words under this topic and sampled word form this distribution. $\\beta$ is parameter of word distribution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 derive the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$As above, $\\vec{\\theta}$ $\\sim$ Dir($\\vec{\\alpha}$), so<br>\n",
    "<center>$p(\\vec{\\theta}|\\vec{\\alpha})$ = $\\frac{\\Gamma(\\sum_{i=1}^{k}\\alpha_i)}{\\prod_{i=1}^{k}\\Gamma(\\alpha_i)}\\theta_1^{\\alpha_1-1} \\cdots \\theta_k^{\\alpha_k-1}$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$$\\vec{\\theta}$ is sampled from Dirichlet Distribution.The reason to use Dirichlet because it will focus on only important words of a document. Thinking one word as a feature, if we only focus on important words, the features could be decreased and thus the dimension will be decreased. So LDA select Dirichlet as prior of $\\vec{\\theta}$ can achieve dimension reduction.<br>\n",
    "<br>\n",
    "$\\quad$Given the parameters $\\alpha$ and $\\beta$, the joint distribution of a topic mixture $\\vec{\\theta}$, a set of N topics $\\vec{z}$ and a set of N words $\\vec{w}$ is given by:<br>\n",
    "<center>p($\\theta$,$\\vec{z}$,$\\vec{w}$ $|$ $\\alpha$,$\\beta$) = p($\\theta$ $|$ $\\alpha$)\n",
    "$\\prod_{n=1}^{N}$ p(z$_n$ $|$ $\\theta$)p(w$_n$ $|$z$_n$,$\\beta$)<center>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$Intergrating over $\\vec{\\theta}$ and summing over z, we obtain the marginal distribution of a document:<br>\n",
    "<br>\n",
    "<center>$p(\\vec{w} | \\alpha,\\beta) =\\int p(\\theta | \\alpha) (\\prod_{n=1}^{N} \\sum_{z_n} p(z_n | \\theta)p(w_n |z_n,\\beta))d\\theta$<center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$Finally, taking the product of the marginal probabilities of single documents, we obtian the probability of a corpus:<br>\n",
    "<br>\n",
    "<center>$p(D | \\alpha,\\beta) =\\prod_{d=1}^{M}\\int p(\\theta_d | \\alpha) (\\prod_{n=1}^{N_d} \\sum_{z_{dn}} p(z_{dn} | \\theta_d)p(w_{dn} | z_{dn},\\beta))d\\theta_d$<center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$The key inferential problem that we need to solve in orde to use LDA is that of computing the posterior distribution of the hidden variables given a document:<br>\n",
    "<center>p($\\vec{\\theta}$,$\\vec{z}$ $|$ $\\vec{w}$,$\\alpha$,$\\beta$) = $\\frac{p(\\vec{\\theta},\\vec{z},\\vec{w} | \\alpha,\\beta)}{p(\\vec{w} | \\alpha,\\beta)}$<center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood:<br>\n",
    "<center>p($\\vec{w}$ $|$ $\\alpha$,$\\beta$) = $\\frac{\\Gamma(\\sum_{i}\\alpha_i)}{\\prod_i\\Gamma(\\alpha_i)}\\int(\\prod_{i=1}^{k}\\theta_i^{\\alpha_i-1})(\\prod_{n=1}^{N}\\sum_{i=1}^{k}\\prod_{j=1}^{V}(\\theta_i\\beta_{ij})^{w_n^j})d\\theta$<center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$However, this function is not intractable due to the product of $\\theta_i$ \n",
    "and \n",
    "$\\beta_{ij}$\n",
    "in the summation over latent variable. So we use Gibbs Sampler to get approximated distribtuion. The alternative solution is using Variational Inference in EM algorithm to get the approximation of posterior of latent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Gibbs Sampler Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$We use Monte Carlo Markov Chain(Gibbs Sampler) to get approximated distribution. We have parameters $\\theta$\n",
    ",$\\phi$ and z. Through Gibbs Sampler, instead of updating these three parameters, we only need to update z since we can removing parameter $\\theta$ and $\\phi$ by integrating over them. Then we use z to update $\\theta$ and $\\phi$.($\\phi$ here is differnet from $\\phi$ in Variational Inference. In Variational Inference, $\\phi$ is latent parameter for topics vector $\\vec{z}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$We apply Gibbs Sampler to get full conditional distribution $p(z_i|\\vec{z}_{-i},\\vec{w})$, which is an approximation of $p(\\vec{z}|\\vec{w})$<br>.\n",
    "$\\quad$To find full conditionals, we focus on joint distribution first.<br>\n",
    "Joint distribution: <br>\n",
    "<center>$p(\\vec{w},\\vec{z}|\\vec{\\alpha},\\vec{\\beta})p(\\vec{z}|\\vec{w}) = p(\\vec{w}|\\vec{z},\\vec{\\beta})p(\\vec{z}|\\vec{\\alpha})$<center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$The first term does not contain $\\alpha$ and the second term does not contain $\\beta$,so we can deal with them separately,<br>\n",
    "<center>$p(\\vec{w}|\\vec{z},\\vec{\\phi}) = \\prod_{i=1}^{w}p(w_i|z_i) = \\prod_{i=1}^{w}\\varphi_{z_i,w_i}$<center>\n",
    "<br>\n",
    "<br>\n",
    "$p(\\vec{w}|\\vec{z},\\vec{\\phi}) = \n",
    "\\prod_{k=1}^{K}\\prod_{i:z_i:=k}p(w_i = t|z_i = k) = \\prod_{k=1}^{K}\\prod_{t=1}^{V}\\varphi_{k,t}^{{n_k}^{(t)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* w:represents the total words in Corpus<br>\n",
    "* ${n_k}^{(t)}$ represents the number of times word t is observed in topic k.\n",
    "Our goal\n",
    "$p(\\vec{w}|\\vec{z},\\vec{\\beta})$ is obtained by integrating over \n",
    "$\\phi$.\n",
    "$\\phi$ is assumed as a known parameter: a matrix with K $\\times$ V dimension. Every entry is the probability of a word under each topic. So each row is one topic and each column is one word.<br>\n",
    "<br>\n",
    "The we integrate over $\\phi$ and we can derive:<br>\n",
    "<center>$P(\\vec{w}|\\vec{z},\\vec{\\beta}) = \\int P(\\vec{w} |\\vec{z},\\phi) P(\\phi|\\vec{\\beta}) d\\phi$\\\\\n",
    "$= \\int \\prod_{k=1}^{K}\\frac{1}{\\Delta \\vec{beta}}\\prod_{t+1}{V}\\varphi_{k,t}^{{n_k}^{(t)}+\\beta_t-1} d\\varphi_k$<br>\n",
    "$= \\prod_{i=1}^{K}\\frac{\\Delta(\\vec{n_k}+\\vec{\\beta})}{\\Delta(\\vec{\\beta})}$,\n",
    "$\\vec{n_k} = \\{{n_k}^{(t)}\\}_{t=1}^{V}$<br><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The vector\n",
    "$\\vec{n}_k$ represents the ditribution of words under topic k, it can be denoted as\n",
    "$\\vec{n}_k$\n",
    "= (the number of word 1 under topic k, the number of word 2 under topic k $\\cdots$).<br>\n",
    "<br>\n",
    "After calculation and simplification, we can get full conditionals:<br>\n",
    "<center>p$(z_i = k|\\vec{z}_{-i},\\vec{w}) = \\frac{p(\\vec{w},\\vec{z})}{p(\\vec{w},\\vec{z}_{-i})} = \\frac{n_i-1 + \\beta_i}{\\sum_{t=1}^{V}(n_{t,-i}+\\beta_t)}\\frac{n_k-1+\\alpha_k}{\\sum_{t=1}{K}(n_{t,-i}+\\alpha_t)}$<br><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $n_i-1$\n",
    ":the number of word i in topic k -1<br>\n",
    "* $p(\\vec{w},\\vec{z}_{-i})$\n",
    ": the probability of word i is from topic k<br>\n",
    "* $n_k-1$\n",
    ": the number of topic under document m -1<br>\n",
    "* $\\sum_{t=1}{K}(n_{t,-i}+\\alpha_t)$\n",
    ": the probability of topic k is from document m<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$Then we use full conditionals to update $\\theta$:distributions of topics and $\\phi$: distributions of words:<br>\n",
    "**update** $\\vec{\\theta}$:<br>\n",
    "$\\theta = [\\vec{\\theta_1},\\vec{\\theta_2}\\cdots,\\vec{\\theta_m}]$<br>\n",
    "$\\theta_{m,k} = \\frac{n_{m.k}+\\alpha_k}{\\sum_{i=1}^{K}(n_{m.i}+\\alpha_i)} = \\frac{n_{m,k}+\\alpha}{\\sum_{i=1}^{K}n_{m,i}+K \\alpha}$<br>\n",
    "<br>\n",
    "**update** $\\vec{\\phi}$<br>\n",
    "$\\phi = [\\vec{\\phi_1},\\vec{\\phi_2}\\cdots,\\vec{\\phi_m}]$<br>\n",
    "$\\phi_{k,w} = \\frac{n_{k,w}+\\beta_w}{\\sum_{i=1}^{V}(n_{k,i}+\\beta_i)} = \\frac{n_{k,w}+\\beta}{\\sum_{i=1}^{V}n_{k,i}+V \\beta}$<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$where $n_{k,i}$ is the number of words in document i that have been assigned to topic k, $n_k,w$ is the total number words assigned to topic k among all documents in the corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$From the above formula, we can see that updating for $\\theta$ and $\\phi$ is only related to topic $z_i$, so we only focus on estimation of $z_i$. To find estimated $z_i$, we need:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $n_{d,z}$: the number of words of document m with topic z, exclude the current word\n",
    "* $n_{z,w}$: the number of instances of word w with topic z, exclude the current word\n",
    "* $n_z$: the taotal number of words under topic z, exclude the current one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior distribution is: <br>\n",
    "<center>$p(z_i=j|z_i,w)\\propto \\frac{n_{zw}+\\phi}{n_z+V \\phi} \\frac{n_{mz}+\\alpha}{n_m + K \\alpha} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pseudo code for update $\\theta$ and $\\phi$ in Gibbs Sampler\n",
    "* input: number of documents: M, number of topics: K, \n",
    "$\\alpha$\n",
    ",\n",
    "$\\beta$\n",
    ",iter$\\_$number<br>\n",
    "* output: theta(doc$\\rightarrow$topic) ,phi(topic$\\rightarrow$word) and tassign(topic assignment)<br>\n",
    "* nw[ ][ ]:number of instances of word/term i assigned to topic j,size V $\\times$ K<br>\n",
    "* nwsum[ ][ ]:total number of words assigned to topic j, size K<br>\n",
    "* nd[ ][ ]:number of topic j is assigned in document i, size M $\\times$ K<br>\n",
    "* ndsum[ ]:total number of words in document i, size M<br>\n",
    "size M $\\times$ per\\_doc\\_word\\_len: the index of word n assigned in doc m "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Cleaning text set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_processor(corpus):\n",
    "    \"\"\"\n",
    "    Split and filter words for each document in corpus.\n",
    "    Create vocabulary and word-id table\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : a valid address of text file and each line in this file\n",
    "    represents a document\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    word_id  : a dictionary \n",
    "               takes vocabulary of corpus as keys and a set of unique \n",
    "               numbers as values\n",
    "    \n",
    "    id_word  : a dictionary\n",
    "               takes a set of unique numbersas keys and vocabulary of \n",
    "               corpus as values\n",
    "               \n",
    "    articles : a list\n",
    "               containing sublists which has the same length as the number\n",
    "               of document in corpus. Each sublist contains a set of ids \n",
    "               coresponding to the words in original document\n",
    "    \"\"\"\n",
    "    word_id  = {}\n",
    "    id_word  = {}\n",
    "    articles = []\n",
    "    ##currentDocument\n",
    "    current_doc    = []\n",
    "    ##currentWordId\n",
    "    current_wordid = 0\n",
    "    for doc in corpus:\n",
    "        ## split words\n",
    "        word_split = doc.split()\n",
    "        for word in word_split:\n",
    "            word = word.lower().strip()\n",
    "            ##the length of word should be bigger than 1 and not contains stop words and punctuation\n",
    "            if len(word) > 1 and word.isalpha() and word not in stopWords:\n",
    "                if word in word_id:\n",
    "                    current_doc.append(word_id[word])\n",
    "                else:\n",
    "                    current_doc.append(current_wordid)\n",
    "                    word_id[word] = current_wordid\n",
    "                    id_word[current_wordid] = word\n",
    "                    current_wordid += 1\n",
    "        articles.append(current_doc)\n",
    "        current_doc = []\n",
    "    return articles, word_id, id_word          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Initialization and Gibbs Sampling Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize(articles,M,K,V,alpha,beta):\n",
    "    \"\"\"\n",
    "    lda gibbs sampler method initilization\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    articles : a list returned by text_processor method\n",
    "    M        : number of document in corpus\n",
    "    K        : number of topic\n",
    "    V        : length of the vocabulary returned by text_processor method\n",
    "    alpha    : prior\n",
    "    beta     : prior\n",
    "    Returns\n",
    "    -------Z,dz_n,,z_n\n",
    "    Z        : list, randomly assign each word in each document\n",
    "               a topic\n",
    "    \n",
    "    dz_n     : a matrix, shape(M,K), initialized distribution of topic\n",
    "               for each document\n",
    "               \n",
    "    zw_n     : a matrix, shape(K,V), initialized distribution of words for\n",
    "               each topic\n",
    "               \n",
    "    z_n      : an array, shape(K), initialized total number of words assigned\n",
    "               to each topic + V*beta\n",
    "    \"\"\"\n",
    "    ZZ         = []                       #need to update \n",
    "    dzz_n      = np.zeros([M, K]) + alpha #document-topic matrix need to update\n",
    "    zww_n      = np.zeros([K, V]) + beta  #dopic-vocabulary need to update\n",
    "    zz_n       = np.zeros([K]) + V * beta #need to update\n",
    "    for d in range(len(articles)):\n",
    "        currentdoc_z = []\n",
    "        for w in articles[d]:\n",
    "            p_z = (dzz_n[d,:]*zww_n[:,w])/zz_n\n",
    "            z   = np.random.multinomial(1,p_z/p_z.sum()).argmax()\n",
    "            currentdoc_z.append(z)\n",
    "            dzz_n[d,z] += 1\n",
    "            zww_n[z,w] += 1\n",
    "            zz_n[z]    += 1\n",
    "        ZZ.append(currentdoc_z)\n",
    "    return ZZ,dzz_n,zww_n,zz_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Gibbs Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gibbs_sampler(iteration,articles,Z,dz_n,zw_n,z_n):\n",
    "    \"\"\"\n",
    "    lda gibbs sampler main method\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    iteration: number of iterations\n",
    "    articles : a list returned by text_processor method\n",
    "    Z        : a list, returned initialize_cython method\n",
    "    dz_n     : a matrix, returned by initialize_cython method\n",
    "    zw_n     : a matrix, returned by initialize_cython method\n",
    "    z_n      : an array, returned by initialize_cython method\n",
    "    \n",
    "    Returns\n",
    "    -------Z,dz_n,,z_n\n",
    "    dz_n     : a matrix, shape(M,K), distribution of topic for each document\n",
    "               \n",
    "    zw_n     : a matrix, shape(K,V), distribution of words for each topic\n",
    "               \n",
    "    z_n      : an array, shape(K), total number of words assigned to each topic\n",
    "    \"\"\"\n",
    "    for i in range(iteration):\n",
    "        for d in range(len(articles)): \n",
    "            for index in range(len(articles[d])):\n",
    "                z = Z[d][index]\n",
    "                #the number of topic correspoding to the word -1\n",
    "                dz_n[d,z] -= 1   \n",
    "                zw_n[z,articles[d][index]] -= 1\n",
    "                z_n[z]    -= 1\n",
    "                p_z        = (dz_n[d,:]*zw_n[:,articles[d][index]])/z_n\n",
    "                z          =  np.random.multinomial(1,p_z/p_z.sum()).argmax() #assign a new topic to this word       \n",
    "                #the number of topic correspoding to the word +1\n",
    "                Z[d][index]= z \n",
    "                dz_n[d,z] += 1 \n",
    "                zw_n[z,articles[d][index]] +=1\n",
    "                z_n[z] +=1\n",
    "    return dz_n,zw_n,z_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Applications to simulated data sets and test original function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\quad$We used simulation to simulate document-topics distribution and topic-words distribution. We simulated 2 topics: w1 represents topics distribution of document1 and w2 represents topics distribution of document2. w1 and w2 are real topics distributions. We simulated 6 words and tow of them are repeated. Since VOCABULARY only counts unique words, so there are 5 words in VOCABULARY. The real words distributions are 3 of them belongs to topic1 and 3 of them belongs to topic2. t00 represents words distribution assigned to topic 1 and t11 represents words distribution under topic2. Our goal is to generate new topic distribution by our implemented lDA algorithm and compare it with the real one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2017)\n",
    "list1 = \"\"\n",
    "list2 = \"\"\n",
    "w1 = [0.3,0.7]\n",
    "w2 = [0.8,0.2]\n",
    "t0 = [0.5,0.25,0.25]\n",
    "t1 = [1/3,1/3,1/3]\n",
    "t00 = {0:\"latent\",1:\"dirichlet\",2:\"allocation\"}\n",
    "t11 = {0:\"latent\",1:\"semantic\",2:\"analysis\"}\n",
    "for i in range(200):\n",
    "    p1 = np.random.multinomial(1,w1).argmax()\n",
    "    if p1 == 0:\n",
    "        p2 = np.random.multinomial(1,t0).argmax()\n",
    "        list1 += t00[p2]+\" \"\n",
    "    else:\n",
    "        p2 = np.random.multinomial(1,t1).argmax()\n",
    "        list1 +=  t11[p2]+\" \"\n",
    "        \n",
    "for j in range(300):\n",
    "    p1 = np.random.multinomial(1,w2).argmax()\n",
    "    if p1 == 0:\n",
    "        p2 = np.random.multinomial(1,t0).argmax()\n",
    "        list2 += t00[p2]+\" \"\n",
    "    else:\n",
    "        p2 = np.random.multinomial(1,t1).argmax()\n",
    "        list2 += t11[p2]+\" \"\n",
    "test_list = [list1,list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles, word_id, id_word = text_processor(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha     = 3                        #prior for each document's topic distribution\n",
    "beta      = 0.1                      #prior for each topic's vocabulary distribution                     #need to update \n",
    "M         = len(articles)            #number of document\n",
    "V         = len(word_id)             #number of vocabulary\n",
    "K         = 2                       #number of chosen topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z1,dz_n1,zw_n1,z_n1 = initialize(articles,M,K,V,alpha,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dz_n_1, zw_n_1,z_n_1 = gibbs_sampler(1000, articles, Z1,dz_n1,zw_n1,z_n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27669903,  0.72330097],\n",
       "       [ 0.80065359,  0.19934641]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_n_1/np.sum(dz_n_1,1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$The new topics distribution generaged by our LDA algorithm is showed above. Under document1, one topic has around 28% probability and another topic has around 72% probability. Under document2, one topic has around 80% prabbility and the other has around 20% probability. The result is highly similar to the real topics distribution, which we simulated above. So the test proves the validation of our LDA algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 optimization for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$In this part, we focus on how to optimize our original LDA algorithm.\n",
    "We mainly use cython to speed up the algorithm, since there are many for loops. In addition, since each iteration of gibbs sampling depends on its previous iteration, vectorization an parallization is impossible in this case. <br>\n",
    "\n",
    "$\\quad$Two main steps we use to speed up the algorithm: try to clearly define each variable and write our own version of multinomial sampling. Here, we want to highlight the second step. Suppose our corpus has 2000 words, we choose 10 topic and run 500 times gibbs sampling. The total number we need run multinomial sampling is $10000000$. As what we showed below this step improve a lot the performance of our algorithm.<br>\n",
    "\n",
    "$\\quad$Finally, we also add a function to compute the perplexity in each iteration for future analysis later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Cython version of initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.stdlib cimport rand, RAND_MAX\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "\n",
    "\n",
    "cdef int multinomial_sampler(double[:] p):\n",
    "    \"\"\"\n",
    "    generate a random number from multinomial distribution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : an array, contains a set of probabilities\n",
    "    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    n  : an integer, \n",
    "         a random index corresponding to the probability which generates it\n",
    "    \"\"\"\n",
    "    cdef double u_idex \n",
    "    cdef int i,j,n\n",
    "    for i in range(1,len(p)):\n",
    "        p[i] += p[i-1]\n",
    "    u_idex = rand()/(RAND_MAX+1.0) * p[len(p)-1]\n",
    "    n = 0\n",
    "    for j in range(0, len(p)):\n",
    "        \n",
    "        if p[j] > u_idex:\n",
    "            n = j\n",
    "            break\n",
    "    return n\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "\n",
    "def initialize_cython(articles,int M,int K,int V,double alpha,double beta):\n",
    "    \"\"\"\n",
    "    lda gibbs sampler method initilization(Cython acceleration vesrion)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    articles : a list returned by text_processor method\n",
    "    M        : number of document in corpus\n",
    "    K        : number of topic\n",
    "    V        : length of the vocabulary returned by text_processor method\n",
    "    alpha    : prior\n",
    "    beta     : prior\n",
    "    Returns\n",
    "    -------Z,dz_n,,z_n\n",
    "    Z        : list, randomly assign each word in each document\n",
    "               a topic\n",
    "    \n",
    "    dz_n     : a matrix, shape(M,K), initialized distribution of topic\n",
    "               for each document\n",
    "               \n",
    "    zw_n     : a matrix, shape(K,V), initialized distribution of words for\n",
    "               each topic\n",
    "               \n",
    "    z_n      : an array, shape(K), initialized total number of words assigned\n",
    "               to each topic + V*beta\n",
    "    \"\"\"\n",
    "    Z         = []                 #need to update\n",
    "    cdef int z                 = 0\n",
    "    cdef int w,d,i,j\n",
    "    cdef double[:, :]dz_n      = np.zeros([M, K]) + alpha #document-topic matrix need to update\n",
    "    cdef double[:, :]zw_n      = np.zeros([K, V]) + beta  #dopic-vocabulary need to update\n",
    "    cdef double[:]z_n          = np.zeros([K]) + V * beta #need to update\n",
    "    cdef double[:]reset = np.zeros([K])\n",
    "    cdef double[:]p_z  = reset\n",
    "    cdef double p_z_sum = 0\n",
    "    cdef double[:]p_z_s = reset\n",
    "    for d in range(len(articles)):\n",
    "        currentdoc_z = []\n",
    "        for w in articles[d]:\n",
    "            for i in range(K):\n",
    "                p_z[i] = (dz_n[d,i]*zw_n[i,w])/z_n[i]\n",
    "                p_z_sum += p_z[i]\n",
    "            for j in range(K):\n",
    "                p_z_s[j] = p_z[j]/p_z_sum\n",
    "            z  = multinomial_sampler(p_z_s)\n",
    "            currentdoc_z.append(z)\n",
    "            dz_n[d,z] += 1\n",
    "            zw_n[z,w] += 1\n",
    "            z_n[z]    += 1\n",
    "            z = 0\n",
    "            p_z_sum = 0\n",
    "            p_z  = reset\n",
    "            p_z_s = reset\n",
    "        Z.append(currentdoc_z)\n",
    "    return Z,dz_n,zw_n,z_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Cython version of gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython \n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.stdlib cimport rand, RAND_MAX\n",
    "from libc.math cimport log,exp\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "\n",
    "cdef double perplexity(articles,double[:,:] dz_n,double[:,:] zw_n, double[:] z_n):\n",
    "    \"\"\"\n",
    "    return perplexity in each iteration\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    articles : a list returned by text_processor method\n",
    "    dz_n     : same as defined in gibbs_sampler_cython\n",
    "    zw_n     : same as defined in gibbs_sampler_cython\n",
    "    z_n      : same as defined in gibbs_sampler_cython\n",
    "   \n",
    "    Returns\n",
    "    -------\n",
    "    1/exp(log_p/n) : perplexity\n",
    "    \"\"\"\n",
    "    cdef int m = dz_n.shape[0]\n",
    "    cdef int kk = dz_n.shape[1]\n",
    "    cdef double[:] d_n = np.zeros(m)\n",
    "    cdef int n = 0\n",
    "    cdef int i,j,k\n",
    "    cdef double log_p = 0.0\n",
    "    cdef double mmm\n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(kk):\n",
    "            d_n[i] += dz_n[i][j]\n",
    "            \n",
    "    for d in range(len(articles)):\n",
    "            for index in range(len(articles[d])):\n",
    "                for k in range(kk):\n",
    "                    mmm += (zw_n[k, articles[d][index]]/z_n[k]) * (dz_n[d, k] / d_n[d])\n",
    "                log_p += log(mmm)\n",
    "                n +=1\n",
    "                mmm = 0\n",
    "    return 1/exp(log_p/n)\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "\n",
    "cdef int multinomial_sampler(double[:] p):\n",
    "    \"\"\"\n",
    "    generate a random number from multinomial distribution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : an array, contains a set of probabilities\n",
    "    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    n  : an integer, \n",
    "         a random index corresponding to the probability which generates it\n",
    "    \"\"\"\n",
    "    cdef double u_idex \n",
    "    cdef int i,j,n\n",
    "    for i in range(1,len(p)):\n",
    "        p[i] += p[i-1]\n",
    "    u_idex = rand()/(RAND_MAX+1.0) * p[len(p)-1]\n",
    "    n = 0\n",
    "    for j in range(0, len(p)):\n",
    "        \n",
    "        if p[j] > u_idex:\n",
    "            n = j\n",
    "            break\n",
    "    return n\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "\n",
    "\n",
    "def gibbs_sampler_cython(int iteration,articles,Z,double[:, :] dz_n, double[:, :] zw_n, double[:] z_n,int K):\n",
    "    \"\"\"\n",
    "    lda gibbs sampler main method(Cython acceleration vesrion)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    iteration: number of iterations\n",
    "    articles : a list returned by text_processor method\n",
    "    Z        : a list, returned initialize_cython method\n",
    "    dz_n     : a matrix, returned by initialize_cython method\n",
    "    zw_n     : a matrix, returned by initialize_cython method\n",
    "    z_n      : an array, returned by initialize_cython method\n",
    "    \n",
    "    Returns\n",
    "    -------Z,dz_n,,z_n\n",
    "    dz_n     : a matrix, shape(M,K), distribution of topic for each document\n",
    "               \n",
    "    zw_n     : a matrix, shape(K,V), distribution of words for each topic\n",
    "               \n",
    "    z_n      : an array, shape(K), total number of words assigned to each topic\n",
    "    \"\"\"\n",
    "    cdef int i,d,index,a_length,w,h\n",
    "    cdef int articles_length = len(articles)\n",
    "    cdef int z                 = 0\n",
    "    \n",
    "    cdef double[:]reset = np.zeros([K])\n",
    "    cdef double[:]p_z   = reset\n",
    "    cdef double p_z_sum = 0\n",
    "    cdef double[:]p_z_s = reset\n",
    "    cdef double[:]perp  = np.zeros([iteration]) \n",
    "    \n",
    "    for i in range(iteration): \n",
    "        for d in range(articles_length):\n",
    "            a_length = len(articles[d])\n",
    "            for index in range(a_length):\n",
    "                z = Z[d][index]\n",
    "                #the number of topic correspoding to the word -1\n",
    "                dz_n[d,z] -= 1\n",
    "                zw_n[z,articles[d][index]] -= 1\n",
    "                z_n[z]    -= 1\n",
    "                \n",
    "                w = articles[d][index]\n",
    "                for h in range(K):\n",
    "                    p_z[h] = (dz_n[d,h]*zw_n[h,w])/z_n[h]\n",
    "                    p_z_sum += p_z[h]\n",
    "                for j in range(K):\n",
    "                    p_z_s[j] = p_z[j]/p_z_sum\n",
    "                z  = multinomial_sampler(p_z_s)\n",
    "                \n",
    "                Z[d][index]= z\n",
    "                #the number of topic correspoding to the word +1\n",
    "                dz_n[d,z] += 1\n",
    "                zw_n[z,w] +=1\n",
    "                z_n[z] +=1\n",
    "                z = 0\n",
    "                p_z_sum = 0\n",
    "                p_z  = reset\n",
    "                p_z_s = reset\n",
    "        perp[i] = perplexity(articles, dz_n, zw_n, z_n)\n",
    "    return dz_n,zw_n,z_n,perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dataset.txt') as f:\n",
    "        docs = [doc.strip() for doc in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles, word_id, id_word = text_processor(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha     = 3                        #prior for each document's topic distribution\n",
    "beta      = 0.1                      #prior for each topic's vocabulary distribution                     #need to update \n",
    "M         = len(articles)            #number of document\n",
    "V         = len(word_id)             #number of vocabulary\n",
    "K         = 10  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 15.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit Z1,dz_n1,zw_n1,z_n1 = initialize(articles,M,K,V,alpha,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.36 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit Z2,dz_n2,zw_n2,z_n2 = initialize_cython(articles,M,K,V,alpha,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z1,dz_n1,zw_n1,z_n1 = initialize(articles,M,K,V,alpha,beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gibbs Sampler Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 17.3 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit dz_n_1, zw_n_1,z_n_1 = gibbs_sampler(1000, articles, Z1,dz_n1,zw_n1,z_n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.57 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit dz_n_2, zw_n_2,z_n_2,perp_2 = gibbs_sampler_cython(1000, articles,Z1,dz_n1,zw_n1,z_n1,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$As what it is shown above, Our cython version algorithms perform very well. In both initialization and gibbs sampler steps, cython version algorithms are 10 times faster than the original ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Function Comparison Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython \n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.stdlib cimport rand, RAND_MAX\n",
    "from libc.math cimport log,exp\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "\n",
    "def multinomial_sampler(p):\n",
    "    \"\"\"\n",
    "    generate a random number from multinomial distribution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : an array, contains a set of probabilities\n",
    "    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    n  : an integer, \n",
    "         a random index corresponding to the probability which generates it\n",
    "    \"\"\"\n",
    "    cdef double u_idex \n",
    "    cdef int i,j,n\n",
    "    for i in range(1,len(p)):\n",
    "        p[i] += p[i-1]\n",
    "    u_idex = rand()/(RAND_MAX+1.0) * p[len(p)-1]\n",
    "    n = 0\n",
    "    for j in range(0, len(p)):\n",
    "        \n",
    "        if p[j] > u_idex:\n",
    "            n = j\n",
    "            break\n",
    "    return n\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cython Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 316 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "l = []\n",
    "p = [0.1,0.3,0.6]\n",
    "for i in range(1000000):\n",
    "    l.append(multinomial_sampler(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3.15 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ll = []\n",
    "pp = [0.1,0.3,0.6]\n",
    "for i in range(1000000):\n",
    "    ll.append(np.random.multinomial(1,pp).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$This experiment show numpy multinomial function is much slower than our own version. It is because numpy multinomial function contain a lot more information which we do not need in our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications to Real Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$The real data consists 100 pieces of news from Associated Press. Associated Press is an American Multinational nonprofit news agency headquartered in New York City that operates as a cooperative, unincorporated association. From this data set, we want to know what is the stlye of Associated Press. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dataset2.txt') as f:\n",
    "        docs_ap = [doc.strip() for doc in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles_ap, word_id_ap, id_word_ap = text_processor(docs_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_ap     = 5                        #prior for each document's topic distribution\n",
    "beta_ap      = 0.2                      #prior for each topic's vocabulary distribution                     #need to update \n",
    "M_ap         = len(articles_ap)            #number of document\n",
    "V_ap         = len(word_id_ap)             #number of vocabularyb                      #number of chosen topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$Here, we set topic to $10,20,30$ respectively. Run our cython version algorihtm to each case, plot their perplexity over iterations and make comparision. Our comparision criterion is based on the perplexity. In information theory, perplexity is a measurement of how well a probability distribution or probability model predicts a sample. It can be used to compare probability models. A low perplexity indicates the probability distribution is good at predicting the sample. Therefore, we would like to choose the topic number with the lowest perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K_ap         = 30\n",
    "Z_ap,dz_n_ap,zw_n_ap,z_n_ap = initialize_cython(articles_ap,M_ap,K_ap,V_ap,alpha_ap,beta_ap)\n",
    "dz_n_ap,zw_n_ap,z_n_ap,perp_ap = gibbs_sampler_cython(200, articles_ap,Z_ap,dz_n_ap,zw_n_ap,z_n_ap,K_ap)\n",
    "perp = np.array(perp_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_ap         = 20\n",
    "Z_ap,dz_n_ap,zw_n_ap,z_n_ap = initialize_cython(articles_ap,M_ap,K_ap,V_ap,alpha_ap,beta_ap)\n",
    "dz_n_ap,zw_n_ap,z_n_ap,perp_ap = gibbs_sampler_cython(200, articles_ap,Z_ap,dz_n_ap,zw_n_ap,z_n_ap,K_ap)\n",
    "perp1 = np.array(perp_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_ap         = 10\n",
    "Z_ap,dz_n_ap,zw_n_ap,z_n_ap = initialize_cython(articles_ap,M_ap,K_ap,V_ap,alpha_ap,beta_ap)\n",
    "dz_n_ap,zw_n_ap,z_n_ap,perp_ap = gibbs_sampler_cython(200, articles_ap,Z_ap,dz_n_ap,zw_n_ap,z_n_ap,K_ap)\n",
    "perp2 = np.array(perp_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGPCAYAAACkrCEWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEMIXJKgRQgghhC9IUCOEEEIIX/h/yO9V6mLHks0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3f25f6e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(np.arange(200)),list(perp2), 'ro', color = 'r')\n",
    "plt.plot(list(np.arange(200)),list(perp1), 'ro', color = 'g')\n",
    "plt.plot(list(np.arange(200)),list(perp), 'ro', color = 'y')\n",
    "\n",
    "plt.title('Perplexity for K=10, K=20, K=30', y=1.08)\n",
    "\n",
    "plt.legend(['K = 10', 'K = 20', 'K = 30'], loc='upper right')\n",
    "\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$From the plot given above, we can see that after 100 iterations, perplexity did not vary a lot and $K = 10$ achieve the lowest perplexity. And we then chose $K = 10$, printed 10 most popular words for each topic and infered the news style of Associated Press. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topicwords = []\n",
    "maxTopicWordsNum = 10\n",
    "for z in range(0, K):\n",
    "    ids = np.array(zw_n_ap[z, :]).argsort()\n",
    "    topicword = []\n",
    "    for j in ids:\n",
    "        topicword.insert(0, id_word_ap[j])\n",
    "    topicwords.append(topicword[0 : min(10, len(topicword))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_words = pd.DataFrame(topicwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>bush</td>\n",
       "      <td>people</td>\n",
       "      <td>police</td>\n",
       "      <td>two</td>\n",
       "      <td>told</td>\n",
       "      <td>dukakis</td>\n",
       "      <td>get</td>\n",
       "      <td>one</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>officials</td>\n",
       "      <td>would</td>\n",
       "      <td>president</td>\n",
       "      <td>two</td>\n",
       "      <td>first</td>\n",
       "      <td>official</td>\n",
       "      <td>union</td>\n",
       "      <td>government</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new</td>\n",
       "      <td>state</td>\n",
       "      <td>states</td>\n",
       "      <td>york</td>\n",
       "      <td>may</td>\n",
       "      <td>could</td>\n",
       "      <td>california</td>\n",
       "      <td>federal</td>\n",
       "      <td>global</td>\n",
       "      <td>summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>president</td>\n",
       "      <td>american</td>\n",
       "      <td>think</td>\n",
       "      <td>administration</td>\n",
       "      <td>good</td>\n",
       "      <td>trade</td>\n",
       "      <td>believe</td>\n",
       "      <td>public</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>central</td>\n",
       "      <td>southern</td>\n",
       "      <td>high</td>\n",
       "      <td>national</td>\n",
       "      <td>wednesday</td>\n",
       "      <td>got</td>\n",
       "      <td>front</td>\n",
       "      <td>fire</td>\n",
       "      <td>reported</td>\n",
       "      <td>record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>said</td>\n",
       "      <td>new</td>\n",
       "      <td>million</td>\n",
       "      <td>also</td>\n",
       "      <td>bank</td>\n",
       "      <td>used</td>\n",
       "      <td>one</td>\n",
       "      <td>barry</td>\n",
       "      <td>jewish</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>soviet</td>\n",
       "      <td>years</td>\n",
       "      <td>gorbachev</td>\n",
       "      <td>many</td>\n",
       "      <td>union</td>\n",
       "      <td>rating</td>\n",
       "      <td>according</td>\n",
       "      <td>three</td>\n",
       "      <td>officers</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>former</td>\n",
       "      <td>defense</td>\n",
       "      <td>state</td>\n",
       "      <td>united</td>\n",
       "      <td>black</td>\n",
       "      <td>saudi</td>\n",
       "      <td>economic</td>\n",
       "      <td>washington</td>\n",
       "      <td>diplomatic</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>scientists</td>\n",
       "      <td>since</td>\n",
       "      <td>also</td>\n",
       "      <td>spacecraft</td>\n",
       "      <td>like</td>\n",
       "      <td>make</td>\n",
       "      <td>magellan</td>\n",
       "      <td>contact</td>\n",
       "      <td>called</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>percent</td>\n",
       "      <td>said</td>\n",
       "      <td>last</td>\n",
       "      <td>oil</td>\n",
       "      <td>rate</td>\n",
       "      <td>prices</td>\n",
       "      <td>company</td>\n",
       "      <td>rose</td>\n",
       "      <td>economy</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2           3               4       5  \\\n",
       "0        said       bush     people      police             two    told   \n",
       "1        said  officials      would   president             two   first   \n",
       "2         new      state     states        york             may   could   \n",
       "3      people  president   american       think  administration    good   \n",
       "4     central   southern       high    national       wednesday     got   \n",
       "5        said        new    million        also            bank    used   \n",
       "6      soviet      years  gorbachev        many           union  rating   \n",
       "7      former    defense      state      united           black   saudi   \n",
       "8  scientists      since       also  spacecraft            like    make   \n",
       "9     percent       said       last         oil            rate  prices   \n",
       "\n",
       "            6           7           8        9  \n",
       "0     dukakis         get         one     back  \n",
       "1    official       union  government     year  \n",
       "2  california     federal      global   summit  \n",
       "3       trade     believe      public  country  \n",
       "4       front        fire    reported   record  \n",
       "5         one       barry      jewish     east  \n",
       "6   according       three    officers   system  \n",
       "7    economic  washington  diplomatic  support  \n",
       "8    magellan     contact      called    group  \n",
       "9     company        rose     economy     year  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$Here, each row in the dataframe above represents a topic. The first topic seems to be related to oil price. The second topic in AP may always make comparsion between New York and California. The third topic is about the union and immigration while the forth one is about justice system. Given these 10 topics we can infer that AP's news is mainly political news. More intereting experiment will be conducted in the furture!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Comparative analysis with Variational EM algorihtms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1  Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$In paper Latent Dirichlet Allocation(Blei, Ng and Jordan(2002)), the authors offered Variational Inference with EM algorithm as solution for computation difficulty of LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distribution of latent variables:<br>\n",
    "<center>$q(\\vec{\\theta},\\vec{z} | \\gamma,\\vec{\\phi}) = q(\\vec{\\theta} | \\gamma) \\prod_{n=1}^{N_i}q(z_n | \\vec{\\phi_n})$<br><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\gamma$: Dirichlet parameter for $\\vec{\\theta}$, variational parameter <br>\n",
    "* $\\vec{\\phi}$: Multinomial parameter for $\\vec{z}$ and can be denoted as $\\phi_1$$\\cdots$ $\\phi_n$,free variatioanl parameter <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$We used Kullback-Leibler(KL) divergence to check the difference between latent distribution and true probability distribution. The value of KL divergence is always greater or equal to 0 and it is equal to 0 if and only if two distributions are same. Then we want to minimize the difference. Our goal is to find parameter <br>\n",
    "* $\\gamma^*$ and $\\phi^*$ that minimize KL divergence using EM algorithm. <br>\n",
    "<center>($\\gamma^*$,$\\phi^*$)=$\\arg\\min_{\\gamma,\\phi}\n",
    "D(q(\\vec{\\theta},\\vec{z} | \\gamma,\\vec{\\phi}) || p(\\vec{\\theta},\\vec{z} | \\vec{w},\\alpha,\\beta))$<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**update $\\vec{\\phi}$**:<br>\n",
    "<center>$\\phi_{ni} \\propto \\beta_{iw_n}exp\\{E_q[log(\\theta_i)| \\gamma]\\}$<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $E_q[log(\\theta_i)| \\gamma] = \\Psi(\\gamma_i) - \\Psi(\\sum_{j=1}^{k}\\gamma_j)$<br>\n",
    "* $\\Psi$: the first derivative of log gamma (log $\\Gamma$) function<br> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**update $\\vec{\\gamma}$**:<br>\n",
    "<center>$\\gamma_i$ = $\\alpha_i$ + $\\sum_{n=1}^{N}$ $\\phi_{ni}$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Pseudo code to calculate $\\phi$ and $\\gamma$ in Variational Inference\n",
    "<quad> initialize $\\phi_{ni}^0$: = 1/K for all i and n<br>\n",
    "initialize $\\gamma_i$: = $\\alpha_i$ +N/k for all i<br>\n",
    "repeat<br>\n",
    "$\\qquad$ for n = 1 to N<br>\n",
    "$\\qquad \\quad$ for i = 1 to K<br>\n",
    "$\\qquad \\qquad$ \n",
    "$\\phi_{ni}^{t+1}$\n",
    ":= $\\beta_{iw_n}$exp($\\Psi$($\\gamma_i^t$))<br>\n",
    "$\\qquad \\quad$ normalize \n",
    "$\\phi_{n}^{t+1}$\n",
    "to sum to 1<br>\n",
    "$\\qquad$ \n",
    "$\\gamma^{t+1}$\n",
    ": = $\\alpha$ + $\\sum_{n=1}^{N}$ $\\phi_{ni}^{t+1}$<br>\n",
    "until convergence<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import psi\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Data Cleaning Function(EM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_processor_em(documents):\n",
    "    \n",
    "    \"\"\"\n",
    "    Split and filter words for each document in corpus.\n",
    "    Create VOCABULARY and word-id table\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus          : a valid address of text file and each line in this file\n",
    "    represents a document\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wordID          : a list with 16 lists inside\n",
    "                      every list repersents index of a word in the document\n",
    "                      \n",
    "    Countword       : a list with 16 lists inside\n",
    "                      every list represents the number of the word in the document\n",
    "                      \n",
    "    singlecount     : a list with 16 lists inside\n",
    "                      every list represents the number of total words in the document\n",
    "                      \n",
    "    word_id         : a dictionary \n",
    "                      takes vocabulary of corpus as keys and a set of unique \n",
    "                      numbers as values\n",
    "    \n",
    "    id_word         : a dictionary\n",
    "                      takes a set of unique numbersas keys and vocabulary of \n",
    "                      corpus as values\n",
    "               \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    stopWords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "    articles = []\n",
    "    word_id = {}\n",
    "    id_word = {}\n",
    "    current_wordid = 0\n",
    "    wordID = []\n",
    "    Countword = []\n",
    "    singlecount = [] \n",
    "    store1 = []\n",
    "    store2 = []\n",
    "    for doc in documents:\n",
    "        word_count = {}\n",
    "            ## split words\n",
    "        word_split = doc.split()\n",
    "        for word in word_split:\n",
    "            word = word.lower().strip()\n",
    "            ##\n",
    "            if (len(word)) > 1 and  word.isalpha() and word not in stopWords:\n",
    "                if word not in word_id:\n",
    "                    word_id[word] = current_wordid\n",
    "                    id_word[current_wordid] = word\n",
    "                    current_wordid += 1\n",
    "                if word in word_count:\n",
    "                    word_count[word] += 1\n",
    "                else:\n",
    "                    word_count[word] = 1\n",
    "                \n",
    "        wordIDList = []\n",
    "        wordCountList = []\n",
    "        wordCount = 0\n",
    "\n",
    "        for word in word_count.keys():\n",
    "            wordIDList.append(word_id[word])\n",
    "            wordCountList.append(word_count[word])\n",
    "            wordCount = wordCount + word_count[word] #total words in a doc\n",
    "        wordID.append(wordIDList)\n",
    "        Countword.append(wordCount)\n",
    "        singlecount.append(wordCountList)\n",
    "        store1.append(wordIDList)\n",
    "        store1.append(wordCountList)\n",
    "        store1.append(wordCount)    \n",
    "        store1 = []\n",
    "        store2.append(store1)\n",
    "    return wordID,Countword,singlecount,word_id,id_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Initialization and EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxwordnum():\n",
    "    \"\"\"\n",
    "    count length of lengest document \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    max(length)          : the lengest length of a document\n",
    "                \n",
    "    \"\"\"\n",
    "    \n",
    "    length = []\n",
    "    for l in wordID:\n",
    "        length.append(len(l))\n",
    "    return max(length)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initial():\n",
    "    \"\"\"\n",
    "    initialize the model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    updatebeta            : a matrix\n",
    "                            updated ny ntw and nt matrix\n",
    "                \n",
    "    \"\"\"\n",
    "    \n",
    "    for z in range(0, K):\n",
    "        for w in range(0, N):\n",
    "            ntw[z, w] += 1.0/N + np.random.random() # probabily of word under every topic\n",
    "            nt[z] += ntw[z, w] \n",
    "    updatebeta(beta,K,N, ntw, nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import cython\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "from libc.math cimport log\n",
    "cimport scipy.special.cython_special\n",
    "from scipy.special.cython_special import psi\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "\n",
    "def updatebeta(double[:,:] beta, int K,int N, double[:,:] ntw, double[:] nt):\n",
    "    \n",
    "    \"\"\"\n",
    "    update beta matrix \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    beta          : A matrix,\n",
    "                    return value from initial method\n",
    "                           \n",
    "    K             : number of topics \n",
    "    N             : length of words\n",
    "    ntw           : topic-words distribution\n",
    "    nt            : words distribution under one topic \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    beta          : updated matrix\n",
    "                \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    cdef int z,w\n",
    "    for z in range(0,K):\n",
    "        for w in range(0,N):\n",
    "            if(ntw[z,w] > 0):\n",
    "                beta[z,w] = beta[z,w] = log(ntw[z,w] / nt[z])\n",
    "            else:\n",
    "                beta[z,w] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import cython\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "from libc.math cimport exp,log\n",
    "cimport scipy.special.cython_special\n",
    "from scipy.special.cython_special import psi\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "\n",
    "def variational(double[:,:] gamma, double[:,:] phi, singlecount,wordID, Countword, double[:,:] beta,\n",
    "                int alpha, int d, int K, int infer_iter):\n",
    "    \"\"\"\n",
    "    Variational with E step\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gamma         : a matrix, shape(M,K), latent parameter of a distribution of topic for each document\n",
    "    phi           : a matrix, shape(K,v), latent parameter of a distribution of words for each topic\n",
    "    wordID        : a list returned by text_processor method\n",
    "    Countword     : a list returned by text_processor method\n",
    "    beta          : a matrix, returned by initial method\n",
    "    alpha         : a fix number \n",
    "    d             : a fix number \n",
    "    K             : number of topics, a fix number\n",
    "    infer_iter    : number of iteration\n",
    "    \n",
    "    Returns\n",
    "    -------gamma\n",
    "    gamma         : updated gamma, a matrix, shape(M,K), distribution of topic for each document\n",
    "   \n",
    "   \"\"\"\n",
    "\n",
    "    cdef int wordlength = len(wordID[d])\n",
    "    cdef double totalphi = 0\n",
    "    cdef double[:] phi_old = np.zeros((K))\n",
    "    cdef double [:] gamma_prime = np.zeros((K))\n",
    "    cdef int z, iteration,w\n",
    "\n",
    "    # initialize parameter\n",
    "    for z in range(K):\n",
    "        #initialize gamma\n",
    "        gamma[d][z] = alpha + Countword[d] * 1.0 / K\n",
    "        gamma_prime[z] = psi(gamma[d][z])\n",
    "        # initialize phi\n",
    "        for w in range(0,len(wordID[d])):\n",
    "            phi[w,z] = 1.0 / K\n",
    "    \n",
    "    for iteration in range(infer_iter):\n",
    "        for w in range(wordlength):\n",
    "            totalphi = 0\n",
    "            for z in range(0,K):\n",
    "                phi_old[z] = phi[w,z]\n",
    "                phi[w,z] = beta[z,wordID[d][w]] + gamma_prime[z]\n",
    "                if z > 0:\n",
    "                    totalphi = log((exp(totalphi)) + exp(phi[w,z]))\n",
    "                else:\n",
    "                    totalphi = phi[w,z]\n",
    "            for z in range(0,K):\n",
    "                phi[w,z] = exp(phi[w,z] - totalphi)\n",
    "                gamma[d][z] = gamma[d][z] + singlecount[d][w] * (phi[w,z] - phi_old[z])\n",
    "                gamma_prime[z] = psi(gamma[d][z]) \n",
    "                \n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5 EM Algorithm Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordID,Countword,singlecount,word_id,id_word = text_processor_em(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = len(wordID)\n",
    "K = 2\n",
    "N = len(word_id)\n",
    "infer_iter = 20\n",
    "EM_iter = 50\n",
    "# inital value for hyperparameter alpha\n",
    "alpha = 5\n",
    "# sufficient statistic of alpha\n",
    "alphass = 0 \n",
    "# topic-word distribution\n",
    "beta = np.zeros((K,N))\n",
    "# topic count, to caculate beta\n",
    "ntw = np.zeros((K,N))\n",
    "# topic count, sum of ntw, to calculate beta\n",
    "nt = np.zeros((K))\n",
    "# variational inference parameter \n",
    "gamma = np.zeros((M,K))\n",
    "phi = np.zeros((maxwordnum(),K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for iteration in range(0,EM_iter):\n",
    "    nt = np.zeros((K))\n",
    "    ntw = np.zeros((K,N))\n",
    "    alphass = 0\n",
    "    \n",
    "        # E step\n",
    "    for d in range(0,M):\n",
    "        variational(gamma, phi, singlecount,wordID, Countword, beta, alpha, d, K, infer_iter)\n",
    "        totalgamma = 0\n",
    "        for z in range(0,K):\n",
    "            totalgamma += gamma[d,z]\n",
    "            alphass += psi(gamma[d,z])\n",
    "        alphass -= K * psi(totalgamma)\n",
    "        \n",
    "        for w in range(len(wordID[d])):\n",
    "            for z in range(0,K):\n",
    "                ntw[z][wordID[d][w]] += singlecount[d][w] * phi[w,z]\n",
    "                nt[z] += singlecount[d][w] * phi[w,z]\n",
    "    # M step\n",
    "    updatebeta(beta,K,N, ntw, nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71447998,  0.28552002],\n",
       "       [ 0.20566964,  0.79433036]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma/np.sum(gamma,1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$Here, we apply implementation of LDA with Variatioal Inference EM on our simulation data. The true topics distribution is as below. Under document 1, one topic has 30% to be assigned and the other topic has 70% to be assigned. Under document1, one topic has around 80% probability and another topic has around 20% probability. The EM algorithm produces a similar result, which for document one, one topic has 28.6 % to be assigned and other topic has 71.4% to be assigned. For document2, one topic has 79.5% to be assigned and other has 20.5%. So the result is highly similar to the true document-topics distribution, which proves the validality of the algorithm.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6 Perplexity Comparison Gibbs Sampler vs Variational EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordID,Countword,singlecount,word_id,id_word = text_processor_em(docs_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = len(wordID)\n",
    "K = 10\n",
    "N = len(word_id)\n",
    "infer_iter = 20\n",
    "EM_iter = 20\n",
    "alpha = 5\n",
    "alphass = 0 \n",
    "beta = np.zeros((K,N))\n",
    "ntw = np.zeros((K,N))\n",
    "nt = np.zeros((K))\n",
    "gamma = np.zeros((M,K))\n",
    "phi = np.zeros((maxwordnum(),K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perp = []\n",
    "for iteration in range(0,EM_iter):\n",
    "    nt = np.zeros((K))\n",
    "    ntw = np.zeros((K,N))\n",
    "    alphass = 0\n",
    "    \n",
    "        # E step\n",
    "    for d in range(0,M):\n",
    "        variational(gamma, phi, singlecount,wordID, Countword, beta, alpha, d, K, infer_iter)\n",
    "        totalgamma = 0\n",
    "        for z in range(0,K):\n",
    "            totalgamma += gamma[d,z]\n",
    "            alphass += psi(gamma[d,z])\n",
    "        alphass -= K * psi(totalgamma)\n",
    "        \n",
    "        for w in range(len(wordID[d])):\n",
    "            for z in range(0,K):\n",
    "                ntw[z][wordID[d][w]] += singlecount[d][w] * phi[w,z]\n",
    "                nt[z] += singlecount[d][w] * phi[w,z]\n",
    "    # M step\n",
    "    updatebeta(beta,K,N, ntw, nt)\n",
    "    \n",
    "    # perplexity\n",
    "    nd = np.sum(np.array(gamma),1)\n",
    "    n = 0\n",
    "    ll = 0.0\n",
    "\n",
    "    for d,doc in enumerate(wordID):\n",
    "        for w in doc:\n",
    "            ll = ll + np.log(((np.array(ntw)[:, w] / np.array(nt))* (np.array(gamma)[d, :] / nd[d])).sum())\n",
    "            n = n + 1\n",
    "            exp_ll = np.exp(ll/(-n))\n",
    "    perp.append(exp_ll) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGPCAYAAACkrCEWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3ee28d6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(np.arange(200)),list(perp2), 'ro', color = 'r')\n",
    "\n",
    "plt.title('Perplexity for LDA with Gibbs Sampling', y=1.08)\n",
    "\n",
    "plt.ylabel(\"perplexity\")\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGPCAYAAACtR4FsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3ee2476a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(np.arange(20)),list(np.array(perp)), 'ro', color = 'r')\n",
    "\n",
    "plt.title('Perplexity for LDA with Varitioanl Inference', y=1.08)\n",
    "\n",
    "plt.ylabel(\"perplexity\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ This part we compare perplexity of LDA implemented with Gibbs Sampler and with Variational Inference EM algorithm. We apply these two algorithms on `dataset2.txt`. From the plots, we can see that the perplexity of LDA with Gibbs Sampler is really high, around 3000, and it converges around 2000 after 50 iterations. The perplexity of LDA with Variational Inference EM starts with around 3700 but covnerge to around 1300 soon after around 10 iterations. So from perplexity, LDA with EM algorithm performs better than Gibbs Sampler. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6 Efficiency Comparison Gibbs Sampler vs Variational EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 5.09 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit dz_n_apt,zw_n_apt,z_n_apt,perp_apt = gibbs_sampler_cython(200, articles_ap,Z_ap,dz_n_ap,zw_n_ap,z_n_ap,K_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 28 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for iteration in range(0,5):\n",
    "    nt = np.zeros((K))\n",
    "    ntw = np.zeros((K,N))\n",
    "    alphass = 0\n",
    "    \n",
    "        # E step\n",
    "    for d in range(0,M):\n",
    "        variational(gamma, phi, singlecount,wordID, Countword, beta, alpha, d, K, infer_iter)\n",
    "        totalgamma = 0\n",
    "        for z in range(0,K):\n",
    "            totalgamma += gamma[d,z]\n",
    "            alphass += psi(gamma[d,z])\n",
    "        alphass -= K * psi(totalgamma)\n",
    "        \n",
    "        for w in range(len(wordID[d])):\n",
    "            for z in range(0,K):\n",
    "                ntw[z][wordID[d][w]] += singlecount[d][w] * phi[w,z]\n",
    "                nt[z] += singlecount[d][w] * phi[w,z]\n",
    "    # M step\n",
    "    updatebeta(beta,K,N, ntw, nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ This part we compare efficiency of LDA implemented with Gibbs Sampler and with Variational Inference EM algorithm. The first time showed is time of Gibbs Sample process, while the second time showed is time of EM algorithm. Gibbs Sampler is obvious faster than EM algorithm. So from efficiency, Gibbs Sampler perfoms better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ LDA is a three-level hierarchical Bayesian model to deal with text data. It is a used approach in unsuper vised machine learning. It performs better than pLSI. The pLSI posits each word of training document comes from a random chosen topic. So the topics are randomly drawed from one specific document. There is only one distribution of topics under a document. However in LDA, document is not fixed, it is also sampled with a parameter. So, LDA is more flexible. LDA has been applied widely for text data. It can achieve document modeling, document classification, and collaborative filtering. We implemented LDA with Gibbs Sampler and Variational Inference. We apply LDA on corpus to find the most popular words under topics. Also it can be used to find latent topics behind documents. To copmare these two algorithms, Variational Inference does well in perplexity while Gibbs Sampler performs better in efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. Journal of\n",
    "Machine Learning Research, 3:993–1022, 2003."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] Associated Press, address https://en.wikipedia.org/wiki/Associated_Press"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3]zhikaizhang, address https://github.com/laserwave/LDA-Variational-EM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
